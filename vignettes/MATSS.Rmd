---
title: "MATSS: Getting Started"
author: 
- Hao Ye
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MATSS: Getting Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
```

# Overview

`MATSS` is a package for conducting Macroecological Analyses of Time Series Structure. We have designed it with researchers in mind, as a tool for getting started quickly to analyzes a large collection of ecological time series (specifically for communities, though the data can also be analyzed as individual populations).

The goals of the package are to make it as easy as possible to:

- obtain a hoard of ecological time series data, processed into a common [data format](data-formats.html)
- build an analysis pipeline, following the workflow framework of the `drake` package; we provide functions to assist with this, as well as project template files

## Installation

You can install the `MATSS` package from github with:

```{r, eval = FALSE}
# install.packages("remotes")
remotes::install_github("weecology/MATSS", build_opts = c("--no-resave-data", "--no-manual")))
```

And load the package in the typical fashion:

```{r, message = FALSE}
library(MATSS)
```

# Template Research Compendium

If you feel comfortable to dive right in, we recommend you start with our provided functionality to create a new research compendium.

This code will perform the following operations:

* create a new R package for the analysis
* add required dependencies for the new R package to its `DESCRIPTION` file
* create an `analysis` folder to hold the analysis files
* add a template R script for the analysis
* add a template Rmd report that is created as a result of running the above R 
  script

After creating the new project, you can source `pipeline.R` to run the analysis and knit the report.

```{r, eval = FALSE}
create_MATSS_compendium("<path>")
```

For further details about how the code within the template project works, see the below guide to interacting with the datasets, the `drake` workflow package, and our tools for building reproducible analyses.

# Data

## Packaged datasets

Several datasets are included with this package - these can be loaded individually using these specific functions, and require no additional setup.

```{r, eval = FALSE}
get_maizuru_data()
get_jornada_data()
get_sgs_data()
get_cowley_lizards()
get_cowley_snakes()
get_karoo_data()
get_kruger_data()
```

## Configuring download locations:

Other datasets require downloading. To facilitate this, we include functions to help configure a specific location on disk. To check your current setting:

```{r, eval = FALSE}
get_default_data_path()
```

and to configure this setting (and then follow the instructions therein):

```{r, eval = FALSE}
use_default_data_path("<path>")
```

## Downloading datasets:

To download individual datasets, call `install_retriever_data()` with the name of the dataset:

```{r, eval = FALSE}
install_retriever_data("veg-plots-sdl")
```

To download all the datasets that are currently supported (i.e. we have functions for importing and processing into the standard format):

```{r, eval = FALSE}
download_datasets()
```

## Preprocessing datasets:

Because the BBS database is an aggregate of observations from multiple locations across North America, it is not the ideal scale for doing community or population analysis. Further, it would be slow to load in the entire database, if only a small section is needed at a time. Thus, we provide a function that processes the database into separate routes and regions, which can be read in individually.

This function will generate and then add processed dataset files to the set download location. This processing is required before running `get_bbs_route_region_data` to load the data.

```{r, eval = FALSE}
prepare_bbs_ts_data()
```

# Working with Drake

For the most part `MATSS` provides only a light wrapper for the functions in `drake`, so it can be helpful to know about how `drake` plans work if you are going to do analyses using `MATSS`. Note that using `drake` plans is not strictly necessary, as you can use the `MATSS` functions in whatever workflow system you desire.

## Basic Workflow

The basic workflow of using `drake` plans is:

* run R code to create `drake` plans
* run R code to take a `drake` plan and execute it

## Provided Helper Functions

We provide several functions to help construct `drake` plans:

* `build_datasets_plan()` constructs a plan for the datasets, with options to include downloaded datasets
* `build_analyses_plan()` constructs a plan for a set of analyses that applies a method to each dataset. It takes as arguments, a plan for the datasets and a plan for the methods.
* `collect_analyses()` combines a set of `drake` targets together into a list, which facilitates later processing
* `analysis_wrapper()` is a function for constructing methods that can operate on the datasets (which are communities) by applying an input argument (which is another function) to each of the individual population time series. (See the example in `?analysis_wrapper` for more information)

Usage of these functions is demonstrated in the template R script generated from `create_MATSS_compendium()`.

### Example

```{r, warning = FALSE}
library(drake)
library(dplyr)

# define the plan
plan <- drake_plan(data_1 = mtcars, 
                   data_2 = iris, 
                   my_model = lm(mpg ~ disp, data = data_1), 
                   my_summary = data_2 %>%
                       group_by(Species) %>%
                       summarize_all(mean))

# run the plan
make(plan)

# check resulting objects
readd(my_model)
readd(my_summary)
```

### Making Drake Plans

A `drake` plan is essentially a `tibble` that defines targets and the commands to build those targets. We can view `drake` plans by printing them to the console:

```{r}
plan # made from the previous example
```

One thing to be aware of is that the function `drake_plan()` does not evaluate its arguments, but only makes the plan. Thus, if you want any evaluation to occur within the construction of the plan, you will need some NSE magic.

In this example, the plan depends on `iris[, column]`, and so the result will necessarily depends on the value of `column`, when the plan is run, as opposed to fixing the value when the drake plan was first created.

```{r}
column <- "Species"
plan <- drake_plan(num_species = nlevels(iris[, column]))

## This computes using the current value of `column` when the analysis is run, 
#    as opposed to on the "Species" column, which was desired: 
column <- "Sepal.Length"
make(plan)
readd(num_species)
```

We can solve this in two ways:

First, we can include `column` as a dependency in the plan:

```{r}
plan <- drake_plan(column = "Species", 
                   num_species = nlevels(iris[, column]))

make(plan)
readd(num_species)
```

Second, make sure that `column` is evaluated when building the plan - this locks in the value of `"Species"`:

```{r}
column <- "Species"
plan <- drake_plan(num_species = nlevels(iris[, !!column]))

## does not require column to be in the current environment
rm(column)
make(plan)
readd(num_species)
```

### Running Drake Plans

Drake plans are run by calling `make()`. This does several things. First it checks the **cache** to see if any targets need to be re-built, and then it proceeds to build all the targets, in some order that accounts for the dependencies between targets. (e.g. an analysis target that depends on a dataset target to be processed)

The manual has more information about how [Drake stores its cache](https://ropenscilabs.github.io/drake-manual/storage.html#cache-formats) and how [Drake decides to rebuild targets](https://ropenscilabs.github.io/drake-manual/triggers.html).

Note that if there are file inputs, it is important that they are declared explicitly using e.g. `file_in()`, `knitr_in()`, and `file_out()`. This enables Drake to check if those files are changed and to rebuild targets that depend on the files if needed. Otherwise Drake will treat them as fixed strings.

```{r, eval = FALSE}
plan <- drake_plan(data = read.csv("some_data.csv"))
make(plan)

# make some changes to `some_data.csv`
make(plan) # will NOT rebuild the `data` target
```

```{r, eval = FALSE}
plan <- drake_plan(data = read.csv(file_in("some_data.csv")))
make(plan)

# make some changes to `some_data.csv`
make(plan) # will rebuild the `data` target
```
